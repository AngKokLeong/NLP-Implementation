{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial:** Text Preprocessing Techniques\n",
        "---\n",
        "\n",
        "Text data seldom come clean. Human communicates using text, and it often contains noise in various forms like emoticons, punctuation, etc.\n",
        "\n",
        "Text preprocessing is an important part of the NLP pipeline. In this tutorial, you will learn about various text preprocessing techniques, such as lowercasing, noise removal, tokenization, stemming, lemmatization, and text normalization.\n",
        "\n",
        "At the end of this tutorial, you will be able to:\n",
        "* explain various text preprocessing techniques in NLP\n",
        "* clean simple texts using basic `python` and several text libraries such as `nltk`, `spacy` and `regex`"
      ],
      "metadata": {
        "id": "x7BbWWSO3Ei2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lowercasing\n",
        "---\n",
        "\n",
        "You will use the same text for all preprocessing shown below. The text is as follows:"
      ],
      "metadata": {
        "id": "DfQDR5OOvf-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Singapore Polytechnic has many courses to help you to upskill and\n",
        "learn. Isn't it great ❤? #sp_nlp #ms9007 #practical-nlp'''\n",
        "\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eQtR8cspoF8X",
        "outputId": "c5f3d077-72bb-4150-aa5f-9075d33e8a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Singapore Polytechnic has many courses to help you to upskill and\\nlearn. Isn't it great ❤? #sp_nlp #ms9007 #practical-nlp\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To lowercase a text, use `text.lower()`."
      ],
      "metadata": {
        "id": "P8fqCNwPvxgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CqjNcvMjv5hP",
        "outputId": "6445d021-1926-4712-ecda-881cff460a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"singapore polytechnic has many courses to help you to upskill and\\nlearn. isn't it great ❤? #sp_nlp #ms9007 #practical-nlp\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing punctuations\n",
        "---"
      ],
      "metadata": {
        "id": "dRoTA1CDwVoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e40f51a8-bac5-49a3-8da6-5d1e6ff4a281",
        "id": "U089qELHwbJR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    no_punctuation = \"\".join([i for i in text if i not in string.punctuation])\n",
        "    return no_punctuation\n",
        "\n",
        "remove_punctuation(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "05e7c4b1-7068-4aad-f260-80259c40fc1c",
        "id": "KVBHtqP6wbJS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Singapore Polytechnic has many courses to help you to upskill and\\nlearn Isnt it great ❤ spnlp ms9007 practicalnlp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "---\n",
        "\n",
        "Tokenization is the process of breaking up a text into smaller parts (called *tokens*). Tokens can be sentences, words, characters, or subwords. The most common tokenization are **sentence tokenization** (a.k.a. sentence segmentation) and **word tokenization**.\n"
      ],
      "metadata": {
        "id": "7te6csmIxiFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentence tokenization\n",
        "---"
      ],
      "metadata": {
        "id": "kWVSaBtUxzck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdnId1NAyFyt",
        "outputId": "b7fe6e85-b6a0-42b8-8191-05c1aca70e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMp5i7tIyYNm",
        "outputId": "3f506401-9cbc-4972-bd43-5b23d307aaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore Polytechnic has many courses to help you to upskill and\\nlearn.',\n",
              " \"Isn't it great ❤?\",\n",
              " '#sp_nlp #ms9007 #practical-nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word tokenization\n",
        "---\n",
        "\n",
        "There are many word tokenizers available in Python. In this course, we will use the `word_tokenize(text)` method from `nltk` package, unless otherwise mentioned."
      ],
      "metadata": {
        "id": "GI7Fa_tWx9Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk word_tokenize (recommended in this course)\n",
        "from nltk import word_tokenize\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "id": "lhK8AF-Yrb6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5dde6e9-abe5-41ce-ec12-88671ba59487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn',\n",
              " '.',\n",
              " 'Is',\n",
              " \"n't\",\n",
              " 'it',\n",
              " 'great',\n",
              " '❤',\n",
              " '?',\n",
              " '#',\n",
              " 'sp_nlp',\n",
              " '#',\n",
              " 'ms9007',\n",
              " '#',\n",
              " 'practical-nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other than the standard `nltk.word_tokenize(text)` method, there exists many other word tokenizers available in various other Python libraries, such as `nltk`, `textblob`, `spacy`, `gensim`, etc.\n",
        "\n",
        "Run the cells below and compare the outputs against the standard `nltk.word_tokenize(text)` output above."
      ],
      "metadata": {
        "id": "HvvDlsMW00I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# manual whitespace tokenization\n",
        "text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rihR_IErtIJ0",
        "outputId": "8daae72a-6d52-43ff-e120-a4cf5776d984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn.',\n",
              " \"Isn't\",\n",
              " 'it',\n",
              " 'great',\n",
              " '❤?',\n",
              " '#sp_nlp',\n",
              " '#ms9007',\n",
              " '#practical-nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ocipsPBGwgsk",
        "outputId": "049c5177-6567-4491-bd6a-dc99e31ced53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Singapore Polytechnic has many courses to help you to upskill and\\nlearn. Isn't it great ❤? #sp_nlp #ms9007 #practical-nlp\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk punctuation-based tokenizer\n",
        "# Note that this tokenizer is a simpler, regular-expression based tokenizer which splits on white space and punctuation.\n",
        "from nltk import wordpunct_tokenize\n",
        "wordpunct_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLZn-DHtr9iV",
        "outputId": "3d34eb20-0f9b-476b-d4c2-ae55f9b1b132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn',\n",
              " '.',\n",
              " 'Isn',\n",
              " \"'\",\n",
              " 't',\n",
              " 'it',\n",
              " 'great',\n",
              " '❤?',\n",
              " '#',\n",
              " 'sp_nlp',\n",
              " '#',\n",
              " 'ms9007',\n",
              " '#',\n",
              " 'practical',\n",
              " '-',\n",
              " 'nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk treebank word tokenizer\n",
        "from nltk import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ast3JmdazyPe",
        "outputId": "670c4556-3489-405f-a342-9af3abfcb389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn.',\n",
              " 'Is',\n",
              " \"n't\",\n",
              " 'it',\n",
              " 'great',\n",
              " '❤',\n",
              " '?',\n",
              " '#',\n",
              " 'sp_nlp',\n",
              " '#',\n",
              " 'ms9007',\n",
              " '#',\n",
              " 'practical-nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Notice that the abbreviation `Isn't` is not split by at the punctuation `'` when using TreebankWordTokenizer, unlike the previous two tokenizer."
      ],
      "metadata": {
        "id": "uTnNX294xdc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using nltk tweet tokenizer\n",
        "from nltk import TweetTokenizer\n",
        "tokenizer = TweetTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXJ3_1v72vOO",
        "outputId": "c87521cd-7c25-4748-ee24-8af86a384a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn',\n",
              " '.',\n",
              " \"Isn't\",\n",
              " 'it',\n",
              " 'great',\n",
              " '❤',\n",
              " '?',\n",
              " '#sp_nlp',\n",
              " '#ms9007',\n",
              " '#practical-nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Textblob:** Documentation [here](https://textblob.readthedocs.io/en/dev/quickstart.html)."
      ],
      "metadata": {
        "id": "mgUj8uof6msO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using textblob\n",
        "from textblob import TextBlob\n",
        "blob_object = TextBlob(text)\n",
        "\n",
        "# word tokenization\n",
        "blob_object.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zONMsgzo3Cku",
        "outputId": "d608d5ce-afaa-4d1e-dc18-c9714f342a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['Singapore', 'Polytechnic', 'has', 'many', 'courses', 'to', 'help', 'you', 'to', 'upskill', 'and', 'learn', 'Is', \"n't\", 'it', 'great', '❤', 'sp_nlp', 'ms9007', 'practical-nlp'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the TextBlob tokenizer removes the punctuations. In addition, it has rules for English contractions."
      ],
      "metadata": {
        "id": "sY2qpvo83ymF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Spacy**: Documentation [here](https://spacy.io/usage/linguistic-features#tokenization)."
      ],
      "metadata": {
        "id": "gJBnyXC47Cuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using spacy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# word tokenization\n",
        "for token in doc:\n",
        "    print(token, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFCaubX03xc1",
        "outputId": "0dfef5f9-399f-4b12-a7eb-e2f946ea6855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singapore PROPN\n",
            "Polytechnic PROPN\n",
            "has VERB\n",
            "many ADJ\n",
            "courses NOUN\n",
            "to PART\n",
            "help VERB\n",
            "you PRON\n",
            "to PART\n",
            "upskill VERB\n",
            "and CCONJ\n",
            "\n",
            " SPACE\n",
            "learn VERB\n",
            ". PUNCT\n",
            "Is AUX\n",
            "n't PART\n",
            "it PRON\n",
            "great ADJ\n",
            "❤ PUNCT\n",
            "? PUNCT\n",
            "# SYM\n",
            "sp_nlp NOUN\n",
            "# SYM\n",
            "ms9007 VERB\n",
            "# DET\n",
            "practical ADJ\n",
            "- PUNCT\n",
            "nlp NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Gensim**"
      ],
      "metadata": {
        "id": "TO5BLjqc7zCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using gensim\n",
        "from gensim.utils import tokenize\n",
        "list(tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRQyzfSW45Hl",
        "outputId": "418277bc-4edb-4d78-8ab4-b3708eaa1c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Singapore',\n",
              " 'Polytechnic',\n",
              " 'has',\n",
              " 'many',\n",
              " 'courses',\n",
              " 'to',\n",
              " 'help',\n",
              " 'you',\n",
              " 'to',\n",
              " 'upskill',\n",
              " 'and',\n",
              " 'learn',\n",
              " 'Isn',\n",
              " 't',\n",
              " 'it',\n",
              " 'great',\n",
              " 'sp_nlp',\n",
              " 'ms',\n",
              " 'practical',\n",
              " 'nlp']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You have seen word tokenization by various Python libraries. Each library has its own advantages and disadvantages. None of them is perfect, and you may want to choose your preferred one, depending on the application at hand."
      ],
      "metadata": {
        "id": "kaX7uXO51gOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing stopwords\n",
        "---\n",
        "\n",
        "First, you need to understand what *stopwords* are.\n",
        "\n",
        "Execute the following cells to print out the common English stopwords in `nltk`."
      ],
      "metadata": {
        "id": "QD6a7-cgmC3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary libraries\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhbeWuHP4VAJ",
        "outputId": "7076823f-c1ca-4fc4-9988-27a07b7cefba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show stopwords list in nltk\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSoDC9q245R5",
        "outputId": "aaf33f0f-2cde-4c8c-e7a8-4c210be33817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you will use the same text as above, and you will remove the punctuations and all the stopwords."
      ],
      "metadata": {
        "id": "w7MkgJam6WpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Singapore Polytechnic has many courses to help you to upskill and \\\n",
        "learn. Isn't it great ❤? #sp_nlp #ms9007 #practical-nlp'''\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    no_punctuation = \"\".join([i for i in text if i not in string.punctuation])\n",
        "    return no_punctuation\n",
        "\n",
        "text_no_punct = remove_punctuation(text)"
      ],
      "metadata": {
        "id": "QodnK9Hp7Y8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "tokens_no_punct = word_tokenize(text_no_punct)\n",
        "tokens_no_punct_stopwords = [w for w in tokens_no_punct \\\n",
        "                            if not w.lower() in stop_words]\n",
        "\n",
        "print(f'Original text: {tokens}')\n",
        "print(f'Remove punctuation: {tokens_no_punct}')\n",
        "print(f'Remove punctuation and stopwords: {tokens_no_punct_stopwords}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y5Jvujc5ebp",
        "outputId": "c29282a5-444f-45f3-e606-8fc8b4e536eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: ['Singapore', 'Polytechnic', 'has', 'many', 'courses', 'to', 'help', 'you', 'to', 'upskill', 'and', 'learn', '.', 'Is', \"n't\", 'it', 'great', '❤', '?', '#', 'sp_nlp', '#', 'ms9007', '#', 'practical-nlp']\n",
            "Remove punctuation: ['Singapore', 'Polytechnic', 'has', 'many', 'courses', 'to', 'help', 'you', 'to', 'upskill', 'and', 'learn', 'Isnt', 'it', 'great', '❤', 'spnlp', 'ms9007', 'practicalnlp']\n",
            "Remove punctuation and stopwords: ['Singapore', 'Polytechnic', 'many', 'courses', 'help', 'upskill', 'learn', 'Isnt', 'great', '❤', 'spnlp', 'ms9007', 'practicalnlp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming / Lemmatization\n",
        "---\n",
        "**Stemming** is a process of reducing words to its root form even if the root has no dictionary meaning.\n",
        "\n",
        "**Lemmatization** is a process of reducing words into their **lemma** or **dictionary word**. It takes into account the meaning of the word in the sentence."
      ],
      "metadata": {
        "id": "V9wBHw1fl6wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "# instantiate stemmers\n",
        "ps = PorterStemmer()\n",
        "ls = LancasterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "sentence = '''Such an analysis can reveal features that are not easily visible\n",
        "from the variations in the individual genes and can lead to a picture of\n",
        "expression that is more biologically transparent and accessible to\n",
        "interpretation'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yg-FF8BqK1s",
        "outputId": "9be095a5-f224-4f9f-bb2f-8c3179c7e9dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = nltk.tokenize.word_tokenize(sentence)\n",
        "\n",
        "stemmed_ps = [ps.stem(word) for word in tokenized_sentence]\n",
        "stemmed_ls = [ls.stem(word) for word in tokenized_sentence]\n",
        "lemmatized = [wnl.lemmatize(word) for word in tokenized_sentence]\n",
        "\n",
        "print(f'Tokenized sentence: {tokenized_sentence}')\n",
        "print(f'Stemmed sentence (porter): {stemmed_ps}')\n",
        "print(f'Stemmed sentence (lancester): {stemmed_ls}')\n",
        "print(f'Lemmatized sentence: {lemmatized}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqDA7JPEmMec",
        "outputId": "52a40dec-668e-47a8-b175-5510408cee2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized sentence: ['Such', 'an', 'analysis', 'can', 'reveal', 'features', 'that', 'are', 'not', 'easily', 'visible', 'from', 'the', 'variations', 'in', 'the', 'individual', 'genes', 'and', 'can', 'lead', 'to', 'a', 'picture', 'of', 'expression', 'that', 'is', 'more', 'biologically', 'transparent', 'and', 'accessible', 'to', 'interpretation']\n",
            "Stemmed sentence (porter): ['such', 'an', 'analysi', 'can', 'reveal', 'featur', 'that', 'are', 'not', 'easili', 'visibl', 'from', 'the', 'variat', 'in', 'the', 'individu', 'gene', 'and', 'can', 'lead', 'to', 'a', 'pictur', 'of', 'express', 'that', 'is', 'more', 'biolog', 'transpar', 'and', 'access', 'to', 'interpret']\n",
            "Stemmed sentence (lancester): ['such', 'an', 'analys', 'can', 'rev', 'feat', 'that', 'ar', 'not', 'easy', 'vis', 'from', 'the', 'vary', 'in', 'the', 'individ', 'gen', 'and', 'can', 'lead', 'to', 'a', 'pict', 'of', 'express', 'that', 'is', 'mor', 'biolog', 'transp', 'and', 'access', 'to', 'interpret']\n",
            "Lemmatized sentence: ['Such', 'an', 'analysis', 'can', 'reveal', 'feature', 'that', 'are', 'not', 'easily', 'visible', 'from', 'the', 'variation', 'in', 'the', 'individual', 'gene', 'and', 'can', 'lead', 'to', 'a', 'picture', 'of', 'expression', 'that', 'is', 'more', 'biologically', 'transparent', 'and', 'accessible', 'to', 'interpretation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display results in the form of table, for comparison\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(\n",
        "    {'Tokenized': tokenized_sentence,\n",
        "     'Porter': stemmed_ps,\n",
        "     'Lancester': stemmed_ls,\n",
        "     'Lemmatized': lemmatized\n",
        "     })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfBQGTA1m4Zv",
        "outputId": "203b009e-5799-43ff-d951-d9eb1fff9232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Tokenized     Porter  Lancester      Lemmatized\n",
              "0             Such       such       such            Such\n",
              "1               an         an         an              an\n",
              "2         analysis    analysi     analys        analysis\n",
              "3              can        can        can             can\n",
              "4           reveal     reveal        rev          reveal\n",
              "5         features     featur       feat         feature\n",
              "6             that       that       that            that\n",
              "7              are        are         ar             are\n",
              "8              not        not        not             not\n",
              "9           easily     easili       easy          easily\n",
              "10         visible     visibl        vis         visible\n",
              "11            from       from       from            from\n",
              "12             the        the        the             the\n",
              "13      variations     variat       vary       variation\n",
              "14              in         in         in              in\n",
              "15             the        the        the             the\n",
              "16      individual   individu    individ      individual\n",
              "17           genes       gene        gen            gene\n",
              "18             and        and        and             and\n",
              "19             can        can        can             can\n",
              "20            lead       lead       lead            lead\n",
              "21              to         to         to              to\n",
              "22               a          a          a               a\n",
              "23         picture     pictur       pict         picture\n",
              "24              of         of         of              of\n",
              "25      expression    express    express      expression\n",
              "26            that       that       that            that\n",
              "27              is         is         is              is\n",
              "28            more       more        mor            more\n",
              "29    biologically     biolog     biolog    biologically\n",
              "30     transparent   transpar     transp     transparent\n",
              "31             and        and        and             and\n",
              "32      accessible     access     access      accessible\n",
              "33              to         to         to              to\n",
              "34  interpretation  interpret  interpret  interpretation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4fb31a0-5baf-4358-afbd-f02874691eca\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tokenized</th>\n",
              "      <th>Porter</th>\n",
              "      <th>Lancester</th>\n",
              "      <th>Lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Such</td>\n",
              "      <td>such</td>\n",
              "      <td>such</td>\n",
              "      <td>Such</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>an</td>\n",
              "      <td>an</td>\n",
              "      <td>an</td>\n",
              "      <td>an</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>analysis</td>\n",
              "      <td>analysi</td>\n",
              "      <td>analys</td>\n",
              "      <td>analysis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>reveal</td>\n",
              "      <td>reveal</td>\n",
              "      <td>rev</td>\n",
              "      <td>reveal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>features</td>\n",
              "      <td>featur</td>\n",
              "      <td>feat</td>\n",
              "      <td>feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>are</td>\n",
              "      <td>are</td>\n",
              "      <td>ar</td>\n",
              "      <td>are</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>not</td>\n",
              "      <td>not</td>\n",
              "      <td>not</td>\n",
              "      <td>not</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>easily</td>\n",
              "      <td>easili</td>\n",
              "      <td>easy</td>\n",
              "      <td>easily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>visible</td>\n",
              "      <td>visibl</td>\n",
              "      <td>vis</td>\n",
              "      <td>visible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>from</td>\n",
              "      <td>from</td>\n",
              "      <td>from</td>\n",
              "      <td>from</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>variations</td>\n",
              "      <td>variat</td>\n",
              "      <td>vary</td>\n",
              "      <td>variation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>individual</td>\n",
              "      <td>individu</td>\n",
              "      <td>individ</td>\n",
              "      <td>individual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>genes</td>\n",
              "      <td>gene</td>\n",
              "      <td>gen</td>\n",
              "      <td>gene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "      <td>can</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>lead</td>\n",
              "      <td>lead</td>\n",
              "      <td>lead</td>\n",
              "      <td>lead</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>picture</td>\n",
              "      <td>pictur</td>\n",
              "      <td>pict</td>\n",
              "      <td>picture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>expression</td>\n",
              "      <td>express</td>\n",
              "      <td>express</td>\n",
              "      <td>expression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "      <td>that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>is</td>\n",
              "      <td>is</td>\n",
              "      <td>is</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>more</td>\n",
              "      <td>more</td>\n",
              "      <td>mor</td>\n",
              "      <td>more</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>biologically</td>\n",
              "      <td>biolog</td>\n",
              "      <td>biolog</td>\n",
              "      <td>biologically</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>transparent</td>\n",
              "      <td>transpar</td>\n",
              "      <td>transp</td>\n",
              "      <td>transparent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>accessible</td>\n",
              "      <td>access</td>\n",
              "      <td>access</td>\n",
              "      <td>accessible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>interpretation</td>\n",
              "      <td>interpret</td>\n",
              "      <td>interpret</td>\n",
              "      <td>interpretation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4fb31a0-5baf-4358-afbd-f02874691eca')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4fb31a0-5baf-4358-afbd-f02874691eca button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4fb31a0-5baf-4358-afbd-f02874691eca');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa7e2961-b9de-44db-acc4-1a1e4f175823\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa7e2961-b9de-44db-acc4-1a1e4f175823')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa7e2961-b9de-44db-acc4-1a1e4f175823 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"     })\",\n  \"rows\": 35,\n  \"fields\": [\n    {\n      \"column\": \"Tokenized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"transparent\",\n          \"individual\",\n          \"expression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Porter\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"transpar\",\n          \"individu\",\n          \"express\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lancester\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"transp\",\n          \"individ\",\n          \"express\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"transparent\",\n          \"individual\",\n          \"expression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the imperfections of the output above too. You would expect \"is\" and \"are\" to be lemmatized to \"be\", but the output above still shows \"is\" and \"are\". This is because `WordNetLemmatizer()` requires the `pos` argument (`pos` = part of speech) to be accurate. The default `pos` has been set to `\"n\"`, which means noun. Refer to the [WordNet documentation](https://www.nltk.org/_modules/nltk/stem/wordnet.html) here."
      ],
      "metadata": {
        "id": "gIYiCiowJVBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notice that the output is incorrect\n",
        "wnl.lemmatize(\"are\")"
      ],
      "metadata": {
        "id": "oq7jSyOWJwRt",
        "outputId": "36844466-945e-45aa-e90a-1639a3b7e63b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'are'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notice now that the output is correct\n",
        "# pos = part of speech: v = verb, a = adjective, r = adverb\n",
        "wnl.lemmatize(\"are\", pos=\"v\")"
      ],
      "metadata": {
        "id": "lZx-pBkoJ2Y2",
        "outputId": "9d365719-8539-4c01-c32d-add3290aca60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'be'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize(\"better\")"
      ],
      "metadata": {
        "id": "MkjbPxm3qz2Z",
        "outputId": "f3451302-692f-4583-b402-16d8e1c3e101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'better'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize(\"better\", pos=\"a\")"
      ],
      "metadata": {
        "id": "b1dV52IjrJb9",
        "outputId": "a61e9572-6541-4f53-bfe8-5bbd838a19fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize(\"better\", pos=\"r\")"
      ],
      "metadata": {
        "id": "2gV7rhQJrTGp",
        "outputId": "cbd51a7b-0452-4673-a6f9-9545474c5dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'well'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by default, pos=\"n\"\n",
        "wnl.lemmatize(\"meeting\")"
      ],
      "metadata": {
        "id": "esmtTVeurj_k",
        "outputId": "8a3de7cb-5a1e-4526-dedb-4a25a3b5e11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'meeting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wnl.lemmatize(\"meeting\", pos=\"v\")"
      ],
      "metadata": {
        "id": "CDmJDu0HtGD7",
        "outputId": "ea2ec595-4b0b-4991-a7b8-7f4b9a3d1bde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'meet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"blue\">**Conclusion**</font>\n",
        "---\n",
        "Congratulations! You have learnt how to use `nltk` for various text preprocessing tasks that you are likely to encounter in your projects.\n",
        "\n",
        "Now, you will further your skill by looking at a case study: how to preprocess social media responses in the form of tweets.\n",
        "\n",
        "Please proceed to the next tutorial."
      ],
      "metadata": {
        "id": "wcpoXlnkHI0m"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}